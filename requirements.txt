# =============================================================================
# AI Log Filter - Production Dependencies
# =============================================================================
# Install with: pip install -r requirements.txt
#
# For development, use: pip install -r requirements-dev.txt
# Or install in editable mode: pip install -e ".[dev]"
# =============================================================================

# Build dependencies (install first if building from source)
# setuptools>=68.0.0
# wheel>=0.40.0

# =============================================================================
# Core Dependencies
# =============================================================================

# Kafka Integration
confluent-kafka>=2.13.0

# Web Framework
fastapi>=0.128.0
uvicorn>=0.40.0

# HTTP Client
httpx>=0.28.1

# Data Processing
numpy>=2.4.1
pandas>=2.3.3
joblib>=1.5.3
pyarrow>=23.0.0
fastparquet>=2025.12.0

# Monitoring & Logging
prometheus-client>=0.24.1
structlog>=25.5.0

# Configuration & Validation
pydantic>=2.12.5
pydantic-settings>=2.12.0
python-dotenv>=1.2.1
pyyaml>=6.0.3

# Rate Limiting
slowapi>=0.1.9

# Progress Bars (for scripts)
tqdm>=4.67.1

# =============================================================================
# Machine Learning Dependencies
# =============================================================================

scikit-learn>=1.8.0
xgboost>=3.1.3

# =============================================================================
# Optional: Cloud Storage (uncomment as needed)
# =============================================================================

# AWS S3 Support
# boto3>=1.34.0
# s3fs>=2024.1.0

# Azure Blob Storage
# azure-storage-blob>=12.19.0

# Google Cloud Storage
# google-cloud-storage>=2.14.0
# gcsfs>=2024.1.0

# =============================================================================
# Optional: Additional Features (uncomment as needed)
# =============================================================================

# Redis for caching/distributed locking
# redis>=5.0.0

# PostgreSQL for metadata storage
# psycopg2-binary>=2.9.9
# asyncpg>=0.29.0

# Elasticsearch for log search
# elasticsearch>=8.11.0

# Vault for secrets management
# hvac>=2.0.0

# =============================================================================
# Optional: ONNX Runtime for Faster Inference (uncomment to enable)
# =============================================================================
# Benefits: 2-10x faster inference, 70-80% smaller models, lower memory usage
#
# Installation:
#   CPU-only:   pip install onnxruntime skl2onnx onnxmltools
#   With GPU:   pip install onnxruntime-gpu skl2onnx onnxmltools
#
# Conversion:
#   python scripts/convert_models_to_onnx.py --input models/v3 --output models/v3/onnx
#
# Uncomment below to enable ONNX support:
# onnxruntime>=1.17.0       # CPU version - recommended for most deployments
# # onnxruntime-gpu>=1.17.0 # GPU version - only if you have NVIDIA GPU
# skl2onnx>=1.16.0          # scikit-learn to ONNX converter
# onnxmltools>=1.12.0       # XGBoost to ONNX converter
