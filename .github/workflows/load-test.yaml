name: ðŸ“Š Load Test

on:
  # Manual trigger with custom parameters
  workflow_dispatch:
    inputs:
      target_eps:
        description: 'ðŸŽ¯ Target Events Per Second'
        required: true
        default: '1000'
        type: string
      duration:
        description: 'â±ï¸ Test duration in seconds'
        required: true
        default: '30'
        type: string
      warmup:
        description: 'ðŸ”¥ Warmup period in seconds'
        required: true
        default: '5'
        type: string

  # Optional: Run on schedule (e.g., weekly)
  schedule:
    - cron: '0 2 * * 0'  # Every Sunday at 2 AM UTC

env:
  PYTHON_VERSION: '3.14'
  UV_VERSION: '0.9.x'

jobs:
  # ===========================================================================
  # âš¡ Performance Load Test
  # ===========================================================================
  load-test:
    name: âš¡ Performance Load Test
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: âš¡ Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: |
            **/pyproject.toml
            **/uv.lock

      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ðŸ“¦ Sync dependencies
        run: uv sync --frozen --extra dev

      - name: ðŸ¤– Validate models before load test
        run: python scripts/validate_models.py

      - name: âš¡ Run load test
        id: load_test
        run: |
          echo "::group::âš¡ Running performance load test"
          python scripts/load_test.py \
            --target-eps ${{ github.event.inputs.target_eps || '1000' }} \
            --duration ${{ github.event.inputs.duration || '30' }} \
            --warmup ${{ github.event.inputs.warmup || '5' }} \
            --output reports/load_test
          echo "::ingroup::"

      - name: ðŸ“¤ Upload load test results
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results-${{ github.run_number }}
          path: reports/load_test/
          retention-days: 30

      - name: ðŸ“Š Generate load test summary
        run: |
          echo "## âš¡ Load Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ“Š Parameter | ðŸ“ˆ Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-------------|----------|" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸŽ¯ Target EPS | ${{ github.event.inputs.target_eps || '1000' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| â±ï¸ Duration | ${{ github.event.inputs.duration || '30' }}s |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ”¥ Warmup | ${{ github.event.inputs.warmup || '5' }}s |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f "reports/load_test/summary.json" ]; then
            echo "### ðŸ“ˆ Results" >> $GITHUB_STEP_SUMMARY
            cat reports/load_test/summary.json | python -c "
            import json, sys
            data = json.load(sys.stdin)
            achieved = data.get('achieved_eps', 'N/A')
            p95 = data.get('p95_latency_ms', 'N/A')
            success = data.get('success_rate', 'N/A')
            print(f'| âš¡ Achieved EPS | {achieved} |')
            print(f'| â±ï¸ P95 Latency | {p95}ms |')
            print(f'| âœ… Success Rate | {success}% |')
            " >> $GITHUB_STEP_SUMMARY
          fi

  # ===========================================================================
  # ðŸ”¥ Chaos/Resilience Test
  # ===========================================================================
  chaos-test:
    name: ðŸ”¥ Chaos/Resilience Test
    runs-on: ubuntu-latest
    needs: load-test
    if: ${{ always() && needs.load-test.result == 'success' }}
    timeout-minutes: 15

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: âš¡ Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: |
            **/pyproject.toml
            **/uv.lock

      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ðŸ“¦ Sync dependencies
        run: uv sync --frozen --extra dev

      - name: ðŸ”¥ Run chaos tests
        run: |
          echo "::group::ðŸ”¥ Running chaos/resilience tests"
          python scripts/chaos_test.py --verbose --output reports/chaos_test
          echo "::ingroup::"

      - name: ðŸ“¤ Upload chaos test results
        uses: actions/upload-artifact@v4
        with:
          name: chaos-test-results-${{ github.run_number }}
          path: reports/chaos_test/
          retention-days: 30

      - name: ðŸ“Š Generate chaos test summary
        run: |
          echo "## ðŸ”¥ Chaos Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… All resilience tests completed. Check artifacts for detailed results." >> $GITHUB_STEP_SUMMARY
